import streamlit as st
import base64

# Configurando a p√°gina
st.set_page_config(page_title="Landing Page", layout="wide")

# Adicionar controle deslizante para ajustar o tamanho do texto
font_size = st.sidebar.slider(
    "Tamanho do texto - Acessibilidade ‚ôø", min_value=10, max_value=40, value=20)

# Definindo o estado de reprodu√ß√£o do √°udio
audio_play = st.sidebar.button("üîä Play √Åudio")

# Carregar o arquivo de √°udio e codificar em base64


def load_audio(file_path):
    with open(file_path, "rb") as audio_file:
        encoded_audio = base64.b64encode(audio_file.read()).decode()
    return encoded_audio


# Verifica se o arquivo de √°udio existe e codifica
audio_file_path = "pages/LLMs.mp3"  # Atualizado para o nome correto
encoded_audio = load_audio(audio_file_path)

# HTML e CSS para o v√≠deo de fundo no corpo principal
background_video_html = """
    <style>
    /* Estiliza o v√≠deo para cobrir todo o fundo do corpo */
    .stApp {
        background-color: rgba(0, 0, 0, 0);
    }

    /* Video styling para ajustar ao fundo */
    #bg-video {
        position: fixed;
        top: 0;
        left: 0;
        min-width: 100%;
        min-height: 100%;
        width: auto;
        height: auto;
        z-index: -1;
        background-size: cover;
        opacity: 0.7;
    }
    </style>

    <video autoplay muted loop id="bg-video">
        <source src="https://cdn.pixabay.com/video/2019/02/11/21287-316701391_large.mp4" type="video/mp4">
    </video>
"""

# HTML para a imagem e o texto
html_content = f"""
    <div style="text-align: center; margin-top: 50px; color: white;">
        <h1 style="font-size: {font_size + 12}px;color: white;">LLMs</h1>
        <p style="font-size: {font_size}px;color: white;">(Large Language Models) Grandes Modelos de Linguagem.</p>
        <img src="https://raw.githubusercontent.com/pasilva1/cashflow/refs/heads/main/robot.png" alt="Exemplo de Imagem" width="500" height="450" style="border-radius: 10px;">
        <p style="font-size: {font_size}px; color: white; margin-top: 20px; ">
            Os LLMs s√£o treinados com grandes quantidades de dados e usam um tipo de rede neural chamada de modelo transformador. Eles podem ser usados para:
            Gerar conte√∫do escrito, como artigos de not√≠cias e scripts de marketing.
            Automa√ß√£o e efici√™ncia, como suporte ao cliente, an√°lise de dados e gera√ß√£o de conte√∫do.
            Gera√ß√£o de insights, como estudar tend√™ncias do mercado e analisar o feedback dos clientes.
            Aperfei√ßoamento da experi√™ncia do cliente, como implementar chatbots e personalizar mensagens de marketing.
            Seguran√ßa cibern√©tica, como identificar padr√µes em dados de seguran√ßa e contribuir na preven√ß√£o de ataques.
            Gera√ß√£o de c√≥digo, como auxiliar os desenvolvedores na constru√ß√£o de aplicativos.
        </p>
    </div>
"""

# Renderizando o HTML no Streamlit para aplicar o background e o conte√∫do
st.markdown(background_video_html, unsafe_allow_html=True)
st.markdown(html_content, unsafe_allow_html=True)

# Adicionando a tag de √°udio embutido no HTML caso o bot√£o seja pressionado
if audio_play:
    audio_html = f"""
    <audio controls autoplay>
        <source src="data:audio/mp3;base64,{encoded_audio}" type="audio/mpeg">
        Seu navegador n√£o suporta a reprodu√ß√£o de √°udio.
    </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True)

# Adicionando uma imagem na barra lateral
with st.sidebar:
    st.image("ai-head-android-robot-artist.gif", use_column_width=True)
